{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9218cb45-3c4e-4be8-ba90-1f7c31e4fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features saved to data/nodes_features.csv\n",
      "Graph is disconnected. Adding edges to connect components...\n",
      "Graph is now connected.\n",
      "Adjacency matrix saved to data/adjacency.csv\n",
      "\n",
      "Synthetic dataset created successfully\n",
      "Using device: cpu\n",
      "Loading and Preprocessing Data\n",
      "Loaded 10 nodes and 9 edges.\n",
      "Starting Node Priority Model Training\n",
      "Epoch   0 | Node Prediction Loss: 0.1090\n",
      "Epoch  20 | Node Prediction Loss: 0.1072\n",
      "Epoch  40 | Node Prediction Loss: 0.1031\n",
      "Epoch  60 | Node Prediction Loss: 0.0496\n",
      "Epoch  80 | Node Prediction Loss: 0.0500\n",
      "Epoch  99 | Node Prediction Loss: 0.0397\n",
      "Training Complete\n",
      "Node predictor model saved to output/node_predictor_model.pt\n",
      "\n",
      "Generating Final Directed Rescue Graph\n",
      "Directed graph visualization saved to output/final_directed_graph.png\n",
      "Adjacency matrix saved to output/final_adjacency_matrix.csv\n",
      "\n",
      "Running Dijkstra from Source Node: 13.1199_77.5763 (Index: 0)\n",
      "Dijkstra graph visualization saved to output/dijkstra_paths_graph.png\n",
      "\n",
      "Final Path Identified (to farthest node: 12.8099_77.5468)\n",
      "Path: 13.1199_77.5763 -> 13.0170_77.5602 -> 12.9259_77.5138 -> 13.1061_77.5484 -> 12.8099_77.5468\n",
      "Cost: 1.6150\n",
      "Final Dijkstra path saved to output/dijkstra_paths.csv\n",
      "\n",
      "Pipeline Finished Successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Import all necessary functions from the modules\n",
    "from synthetic_dataset import generate_synthetic_dataset\n",
    "from preprocessing.load import load_node_features, load_adjacency_matrix, normalize_features\n",
    "from preprocessing.build_graph import build_nx_graph, build_pyg_graph\n",
    "from model.gnn import GraphSAGEPredictor, seed_all\n",
    "from training.train import train_node_predictor, create_directed_graph_from_scores, save_and_visualize_graph\n",
    "from model.model_utils import save_node_model\n",
    "from training.run_dijkstra import run_dijkstra_analysis\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Sentry Drone GNN pipeline.\n",
    "    \"\"\"\n",
    "    # 1.5. Generate Synthetic Dataset (Temporary)\n",
    "    generate_synthetic_dataset(num_nodes=10)\n",
    "\n",
    "    # 2. Setup & Configuration\n",
    "    seed_all(42)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    NODES_CSV_PATH = \"data/nodes_features.csv\"\n",
    "    ADJ_CSV_PATH = \"data/adjacency.csv\"\n",
    "    MODEL_SAVE_PATH = \"output/node_predictor_model.pt\"\n",
    "\n",
    "    # 3. Data Loading and Preprocessing\n",
    "    print(\"Loading and Preprocessing Data\")\n",
    "    node_ids, features = load_node_features(NODES_CSV_PATH)\n",
    "    _, adj_matrix = load_adjacency_matrix(ADJ_CSV_PATH)\n",
    "    \n",
    "    # Normalize features for the model\n",
    "    features_normalized = normalize_features(features)\n",
    "\n",
    "    # Build graphs: NetworkX for structure/visualization, PyG for training\n",
    "    nx_graph = build_nx_graph(node_ids, features, adj_matrix)\n",
    "    pyg_graph = build_pyg_graph(node_ids, features_normalized, adj_matrix)\n",
    "    \n",
    "    print(f\"Loaded {nx_graph.number_of_nodes()} nodes and {nx_graph.number_of_edges()} edges.\")\n",
    "\n",
    "    # 4. Model Training\n",
    "    # Prepare labels for training\n",
    "    # For this example, we use the 'signs_of_life_score' (column index 2) as the target priority\n",
    "    node_labels = torch.tensor(features_normalized[:, 2], dtype=torch.float)\n",
    "\n",
    "    # Initialize the node predictor model\n",
    "    model = GraphSAGEPredictor(\n",
    "        in_channels=features_normalized.shape[1],\n",
    "        hidden_channels=64,\n",
    "        num_layers=2,\n",
    "        aggr=\"max\"\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trained_model, history = train_node_predictor(\n",
    "        model=model,\n",
    "        data=pyg_graph,\n",
    "        node_labels=node_labels,\n",
    "        epochs=100,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 5. Save the Trained Model\n",
    "    save_node_model(trained_model, path=MODEL_SAVE_PATH)\n",
    "\n",
    "    # 6. Prediction and Directed Graph Generation\n",
    "    print(\"\\nGenerating Final Directed Rescue Graph\")\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_node_scores = trained_model(pyg_graph.to(device)).cpu().numpy()\n",
    "    \n",
    "    # Create the final directed graph based on predicted scores\n",
    "    final_directed_graph = create_directed_graph_from_scores(nx_graph, final_node_scores)\n",
    "    \n",
    "    # Visualize and save the final outputs (image and adjacency matrix)\n",
    "    save_and_visualize_graph(final_directed_graph, final_node_scores, output_dir='output')\n",
    "\n",
    "    # Visualize and save the final graph based on Dijkstra's Shortest Path for Comparison\n",
    "    run_dijkstra_analysis()\n",
    "    \n",
    "    print(\"\\nPipeline Finished Successfully\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c5fa6a-637b-4d08-ae82-b0bad7c182c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prediction on Device: cpu\n",
      "Loading trained model from output/node_predictor_model.pt...\n",
      "Node predictor model loaded from output/node_predictor_model.pt\n",
      "Loading test data from data/test_nodes_features.csv...\n",
      "Calculating scaler from training data...\n",
      "Normalizing test data...\n",
      "Building graphs for test data...\n",
      "Running model prediction...\n",
      "Generating and saving final rescue graph...\n",
      "Directed graph visualization saved to output_test/final_directed_graph.png\n",
      "Adjacency matrix saved to output_test/final_adjacency_matrix.csv\n",
      "\n",
      "Prediction Complete. Results saved in 'output_test' folder.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from preprocessing.load import load_node_features, load_adjacency_matrix\n",
    "from preprocessing.build_graph import build_nx_graph, build_pyg_graph\n",
    "from model.model_utils import load_node_model\n",
    "from training.train import create_directed_graph_from_scores, save_and_visualize_graph\n",
    "\n",
    "def get_scaler_from_training_data(training_csv_path: str):\n",
    "    \"\"\"\n",
    "    Calculates the min and max values from the training data for normalization\n",
    "    \"\"\"\n",
    "    _, features = load_node_features(training_csv_path)\n",
    "    min_vals = features.min(axis=0)\n",
    "    max_vals = features.max(axis=0)\n",
    "    return min_vals, max_vals\n",
    "\n",
    "def normalize_test_features(features: np.ndarray, min_vals: np.ndarray, max_vals: np.ndarray):\n",
    "    \"\"\"\n",
    "    Normalizes test data using the scaler from the training data\n",
    "    \"\"\"\n",
    "    ranges = max_vals - min_vals\n",
    "\n",
    "    # Avoid division by zero if a feature had no range in the training data\n",
    "    denom = ranges.copy()\n",
    "    denom[denom == 0] = 1\n",
    "\n",
    "    normalized = (features - min_vals) / denom\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def predict_on_test_data():\n",
    "    \"\"\"\n",
    "    Loads a trained model and runs predictions on new, unseen test data.\n",
    "    \"\"\"\n",
    "    TRAINING_NODES_CSV = \"data/nodes_features.csv\"\n",
    "    TEST_NODES_CSV = \"data/test_nodes_features.csv\"\n",
    "    TEST_ADJ_CSV = \"data/test_adjacency.csv\"\n",
    "    MODEL_PATH = \"output/node_predictor_model.pt\"\n",
    "    OUTPUT_DIR = \"output_test\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Running Prediction on Device: {device}\")\n",
    "\n",
    "    print(f\"Loading trained model from {MODEL_PATH}...\")\n",
    "    try:\n",
    "        model = load_node_model(path=MODEL_PATH, device=device)\n",
    "        model.eval() # set model to evaluation mode\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {MODEL_PATH}. Please run the training script first.\")\n",
    "        return\n",
    "\n",
    "    # Load and Preprocess Test Data\n",
    "    print(f\"Loading test data from {TEST_NODES_CSV}...\")\n",
    "    try:\n",
    "        test_node_ids, test_features = load_node_features(TEST_NODES_CSV)\n",
    "        _, test_adj_matrix = load_adjacency_matrix(TEST_ADJ_CSV)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Test data files not found. Please create them.\")\n",
    "        return\n",
    "\n",
    "    # Get scaler from Training data\n",
    "    print(\"Calculating scaler from training data...\")\n",
    "    min_vals, max_vals = get_scaler_from_training_data(TRAINING_NODES_CSV)\n",
    "    \n",
    "    # Normalize Test data using the training scaler\n",
    "    print(\"Normalizing test data...\")\n",
    "    test_features_normalized = normalize_test_features(test_features, min_vals, max_vals)\n",
    "\n",
    "    # Build Graphs for Test Data\n",
    "    print(\"Building graphs for test data...\")\n",
    "    test_nx_graph = build_nx_graph(test_node_ids, test_features, test_adj_matrix)\n",
    "    test_pyg_graph = build_pyg_graph(test_node_ids, test_features_normalized, test_adj_matrix)\n",
    "\n",
    "    # Run Prediction\n",
    "    print(\"Running model prediction...\")\n",
    "    with torch.no_grad():\n",
    "        node_scores = model(test_pyg_graph.to(device)).cpu().numpy()\n",
    "\n",
    "    # Generate and Save Final Output\n",
    "    print(\"Generating and saving final rescue graph...\")\n",
    "    final_directed_graph = create_directed_graph_from_scores(test_nx_graph, node_scores)\n",
    "    \n",
    "    save_and_visualize_graph(\n",
    "        final_directed_graph, \n",
    "        node_scores, \n",
    "        output_dir=OUTPUT_DIR\n",
    "    )\n",
    "    print(f\"\\nPrediction Complete. Results saved in '{OUTPUT_DIR}' folder.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predict_on_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062ee42-4ba9-48cc-8a4f-99dd6cb3cbef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gcn_env)",
   "language": "python",
   "name": "gcn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
